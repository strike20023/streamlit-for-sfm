{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class CustomDecisionTree:\n",
    "    def __init__(self, max_depth=3, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y, features_per_level):\n",
    "        self.tree = self._build_tree(X, y, features_per_level, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, features_per_level, depth):\n",
    "        if depth == self.max_depth or len(X) < self.min_samples_split:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        feature_indices = features_per_level[depth % len(features_per_level)]\n",
    "        best_feature, best_threshold = self._find_best_split(X, y, feature_indices)\n",
    "        \n",
    "        if best_feature is None:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        left_indices = X[:, best_feature] <= best_threshold\n",
    "        right_indices = X[:, best_feature] > best_threshold\n",
    "        \n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], features_per_level, depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], features_per_level, depth + 1)\n",
    "        \n",
    "        return {\"feature\": best_feature, \"threshold\": best_threshold, \"left\": left_tree, \"right\": right_tree}\n",
    "\n",
    "    def _find_best_split(self, X, y, feature_indices):\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_gain = -np.inf\n",
    "        \n",
    "        for feature in feature_indices:\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(X, y, feature, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _information_gain(self, X, y, feature, threshold):\n",
    "        left_indices = X[:, feature] <= threshold\n",
    "        right_indices = X[:, feature] > threshold\n",
    "        \n",
    "        if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n",
    "            return 0\n",
    "        \n",
    "        p_left = len(y[left_indices]) / len(y)\n",
    "        p_right = len(y[right_indices]) / len(y)\n",
    "        \n",
    "        return self._entropy(y) - (p_left * self._entropy(y[left_indices]) + p_right * self._entropy(y[right_indices]))\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        probabilities = [np.mean(y == c) for c in np.unique(y)]\n",
    "        return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_one(x, self.tree) for x in X])\n",
    "    \n",
    "    def _predict_one(self, x, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        \n",
    "        if x[tree[\"feature\"]] <= tree[\"threshold\"]:\n",
    "            return self._predict_one(x, tree[\"left\"])\n",
    "        else:\n",
    "            return self._predict_one(x, tree[\"right\"])\n",
    "    \n",
    "    def to_dot(self, feature_names=None):\n",
    "        dot_representation = [\"digraph Tree {\"]\n",
    "        self._to_dot_helper(self.tree, dot_representation, feature_names)\n",
    "        dot_representation.append(\"}\")\n",
    "        return \"\\n\".join(dot_representation)\n",
    "    \n",
    "    def _to_dot_helper(self, tree, dot_representation, feature_names, node_id=0, parent_id=None, label=None):\n",
    "        if isinstance(tree, dict):\n",
    "            feature = feature_names[tree[\"feature\"]] if feature_names else f\"X{tree['feature']}\"\n",
    "            threshold = tree[\"threshold\"]\n",
    "            node_label = f'{feature} <= {threshold:.2f}'\n",
    "            \n",
    "            dot_representation.append(f'node{node_id} [label=\"{node_label}\"];')\n",
    "            if parent_id is not None:\n",
    "                dot_representation.append(f'node{parent_id} -> node{node_id} [label=\"{label}\"];')\n",
    "            \n",
    "            left_id = node_id * 2 + 1\n",
    "            right_id = node_id * 2 + 2\n",
    "            \n",
    "            self._to_dot_helper(tree[\"left\"], dot_representation, feature_names, left_id, node_id, \"True\")\n",
    "            self._to_dot_helper(tree[\"right\"], dot_representation, feature_names, right_id, node_id, \"False\")\n",
    "        else:\n",
    "            node_label = f\"leaf: {tree:.2f}\"\n",
    "            dot_representation.append(f'node{node_id} [label=\"{node_label}\", shape=box];')\n",
    "            if parent_id is not None:\n",
    "                dot_representation.append(f'node{parent_id} -> node{node_id} [label=\"{label}\"];')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  1.  0.5 0.5 0. ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 示例数据\n",
    "data = {\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': [5, 4, 3, 2, 1],\n",
    "    'feature3': [2, 3, 4, 5, 6],\n",
    "    'target': [0, 1, 0, 1, 0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 特征矩阵和目标向量\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# 每一层分支的特征索引\n",
    "features_per_level = [[0, 2], [1, 2], [0, 1]]\n",
    "\n",
    "# 初始化和训练模型\n",
    "clf = CustomDecisionTree(max_depth=3, min_samples_split=2)\n",
    "clf.fit(X, y, features_per_level)\n",
    "\n",
    "# 预测\n",
    "predictions = clf.predict(X)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph Tree {\n",
      "node0 [label=\"feature1 <= 1.00\"];\n",
      "node1 [label=\"leaf: 0.00\", shape=box];\n",
      "node0 -> node1 [label=\"True\"];\n",
      "node2 [label=\"feature2 <= 1.00\"];\n",
      "node0 -> node2 [label=\"False\"];\n",
      "node5 [label=\"leaf: 0.00\", shape=box];\n",
      "node2 -> node5 [label=\"True\"];\n",
      "node6 [label=\"feature1 <= 2.00\"];\n",
      "node2 -> node6 [label=\"False\"];\n",
      "node13 [label=\"leaf: 1.00\", shape=box];\n",
      "node6 -> node13 [label=\"True\"];\n",
      "node14 [label=\"leaf: 0.50\", shape=box];\n",
      "node6 -> node14 [label=\"False\"];\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class CustomDecisionTree:\n",
    "    def __init__(self, max_depth=3, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y, features_per_level):\n",
    "        self.tree = self._build_tree(X, y, features_per_level, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, features_per_level, depth):\n",
    "        if depth == self.max_depth or len(X) < self.min_samples_split:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        feature_indices = features_per_level[depth % len(features_per_level)]\n",
    "        best_feature, best_threshold = self._find_best_split(X, y, feature_indices)\n",
    "        \n",
    "        if best_feature is None:\n",
    "            return np.mean(y)\n",
    "        \n",
    "        left_indices = X[:, best_feature] <= best_threshold\n",
    "        right_indices = X[:, best_feature] > best_threshold\n",
    "        \n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], features_per_level, depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], features_per_level, depth + 1)\n",
    "        \n",
    "        return {\"feature\": best_feature, \"threshold\": best_threshold, \"left\": left_tree, \"right\": right_tree}\n",
    "\n",
    "    def _find_best_split(self, X, y, feature_indices):\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_gain = -np.inf\n",
    "        \n",
    "        for feature in feature_indices:\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(X, y, feature, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _information_gain(self, X, y, feature, threshold):\n",
    "        left_indices = X[:, feature] <= threshold\n",
    "        right_indices = X[:, feature] > threshold\n",
    "        \n",
    "        if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n",
    "            return 0\n",
    "        \n",
    "        p_left = len(y[left_indices]) / len(y)\n",
    "        p_right = len(y[right_indices]) / len(y)\n",
    "        \n",
    "        return self._entropy(y) - (p_left * self._entropy(y[left_indices]) + p_right * self._entropy(y[right_indices]))\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        probabilities = [np.mean(y == c) for c in np.unique(y)]\n",
    "        return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_one(x, self.tree) for x in X])\n",
    "    \n",
    "    def _predict_one(self, x, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        \n",
    "        if x[tree[\"feature\"]] <= tree[\"threshold\"]:\n",
    "            return self._predict_one(x, tree[\"left\"])\n",
    "        else:\n",
    "            return self._predict_one(x, tree[\"right\"])\n",
    "\n",
    "    def to_dot(self, feature_names=None):\n",
    "        dot_representation = [\"digraph Tree {\"]\n",
    "        self._to_dot_helper(self.tree, dot_representation, feature_names)\n",
    "        dot_representation.append(\"}\")\n",
    "        return \"\\n\".join(dot_representation)\n",
    "    \n",
    "    def _to_dot_helper(self, tree, dot_representation, feature_names, node_id=0, parent_id=None, label=None):\n",
    "        if isinstance(tree, dict):\n",
    "            feature = feature_names[tree[\"feature\"]] if feature_names is not None else f\"X{tree['feature']}\"\n",
    "            threshold = tree[\"threshold\"]\n",
    "            node_label = f'{feature} <= {threshold:.2f}'\n",
    "            \n",
    "            dot_representation.append(f'node{node_id} [label=\"{node_label}\"];')\n",
    "            if parent_id is not None:\n",
    "                dot_representation.append(f'node{parent_id} -> node{node_id} [label=\"{label}\"];')\n",
    "            \n",
    "            left_id = node_id * 2 + 1\n",
    "            right_id = node_id * 2 + 2\n",
    "            \n",
    "            self._to_dot_helper(tree[\"left\"], dot_representation, feature_names, left_id, node_id, \"True\")\n",
    "            self._to_dot_helper(tree[\"right\"], dot_representation, feature_names, right_id, node_id, \"False\")\n",
    "        else:\n",
    "            node_label = f\"leaf: {tree:.2f}\"\n",
    "            dot_representation.append(f'node{node_id} [label=\"{node_label}\", shape=box];')\n",
    "            if parent_id is not None:\n",
    "                dot_representation.append(f'node{parent_id} -> node{node_id} [label=\"{label}\"];')\n",
    "\n",
    "# 示例数据\n",
    "data = {\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': [5, 4, 3, 2, 1],\n",
    "    'feature3': [2, 3, 4, 5, 6],\n",
    "    'target': [0, 1, 0, 1, 0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 特征矩阵和目标向量\n",
    "X = df.drop(columns=['target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# 每一层分支的特征索引\n",
    "features_per_level = [[0, 2], [1, 2], [0, 1]]\n",
    "\n",
    "# 初始化和训练模型\n",
    "clf = CustomDecisionTree(max_depth=3, min_samples_split=2)\n",
    "clf.fit(X, y, features_per_level)\n",
    "\n",
    "# 将决策树转换为DOT格式\n",
    "dot_representation = clf.to_dot(feature_names=df.drop(columns=['target']).columns.tolist())\n",
    "print(dot_representation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
